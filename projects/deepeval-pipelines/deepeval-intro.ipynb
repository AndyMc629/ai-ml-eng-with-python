{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5be28b0-732a-4a4e-b3ee-dc1abfd1d053",
   "metadata": {},
   "source": [
    "# LLMOps with DeepEval\n",
    "\n",
    "LLMOps covers:\n",
    "1. **Testing**\n",
    "2. **Evaluation**\n",
    "3. **Monitoring**\n",
    "4. Infrastructure\n",
    "5. Orchestration\n",
    "6. Deployment\n",
    "\n",
    "We will discuss how to use the [DeepEval library](https://deepeval.com/) (and Confident-AI platform) to help you with 1,2 and 3.\n",
    "\n",
    "**Resources**\n",
    "- https://github.com/confident-ai/deepeval/blob/main/examples/notebooks/langgraph.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b610b937-d447-4d5d-9d15-1ba8fd76f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPEN_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b09293-bacf-4d71-8f51-8f3d3f366cad",
   "metadata": {},
   "source": [
    "## 1. Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d42876c9-80e5-4a25-8311-a2c2f452288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval import assert_test\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import GEval\n",
    "\n",
    "def test_correctness():\n",
    "    correctness_metric = GEval(\n",
    "        name=\"Correctness\",\n",
    "        criteria=\"Determine if the 'actual output' is correct based on the 'expected output'.\",\n",
    "        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    "        threshold=0.5\n",
    "    )\n",
    "    test_case = LLMTestCase(\n",
    "        input=\"I have a persistent cough and fever. Should I be worried?\",\n",
    "        # Replace this with the actual output from your LLM application\n",
    "        actual_output=\"A persistent cough and fever could be a viral infection or something more serious. See a doctor if symptoms worsen or don't improve in a few days.\",\n",
    "        expected_output=\"A persistent cough and fever could indicate a range of illnesses, from a mild viral infection to more serious conditions like pneumonia or COVID-19. You should seek medical attention if your symptoms worsen, persist for more than a few days, or are accompanied by difficulty breathing, chest pain, or other concerning signs.\"\n",
    "    )\n",
    "    assert_test(test_case, [correctness_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d73b2e-52eb-4292-908e-5d21f7b1b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPEN_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96574d55-c781-4361-ae6e-abcac372eeb7",
   "metadata": {},
   "source": [
    "## 1. RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0844cf2f-11d4-41f4-a40d-b0fd2b81c95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 18482  100 18482    0     0  43839      0 --:--:-- --:--:-- --:--:-- 43900\n"
     ]
    }
   ],
   "source": [
    "!curl -o src/manual.txt \"https://confident-bucket.s3.us-east-1.amazonaws.com/manual.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c68a558e-8a5c-4225-ae76-9c3aba668aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.langgraph_rag_agent import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f8841-577c-497f-b9fc-e0eef10249c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b44af1d-d17b-4e80-acbd-eecf164f8e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The average heart rate of the user is 94 beats per minute.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "initial_state = {\n",
    "    \"query\": \"\",\n",
    "    \"selected_tools\": [],\n",
    "    \"retrieved_context\": \"\",\n",
    "    \"tool_outputs\": [],\n",
    "    \"next_action\": \"\",\n",
    "}\n",
    "\n",
    "\n",
    "def run_rag_query(query: str):\n",
    "    \"\"\"Run a query through the RAG system\"\"\"\n",
    "\n",
    "    initial_state[\"messages\"] = [HumanMessage(content=query)]\n",
    "    result = app.invoke(initial_state)\n",
    "    final_message = result[\"messages\"][-1]\n",
    "    return final_message.content\n",
    "\n",
    "\n",
    "run_rag_query(\"What is the average heart rate of the user?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e13653ba-5f65-42fa-a3cc-8166bc6d09f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"While the context provided does not contain specific tips for fitness, I can offer some general advice based on widely accepted fitness principles:\\n\\n1. **Set Clear Goals**: Define what you want to achieve, whether it's weight loss, muscle gain, improved endurance, or overall health.\\n\\n2. **Create a Balanced Routine**: Incorporate a mix of cardiovascular exercise, strength training, and flexibility workouts. This helps improve overall fitness and reduces the risk of injury.\\n\\n3. **Stay Consistent**: Regular exercise is key to achieving and maintaining fitness. Aim for at least 150 minutes of moderate aerobic activity or 75 minutes of vigorous activity each week, along with strength training on two or more days.\\n\\n4. **Listen to Your Body**: Pay attention to how your body feels during and after workouts. Rest and recovery are just as important as the workouts themselves.\\n\\n5. **Stay Hydrated**: Drink plenty of water before, during, and after exercise to maintain hydration and support performance.\\n\\n6. **Eat a Balanced Diet**: Fuel your body with a variety of nutrients. Focus on whole foods, including fruits, vegetables, lean proteins, whole grains, and healthy fats.\\n\\n7. **Get Enough Sleep**: Quality sleep is crucial for recovery and overall health. Aim for 7-9 hours of sleep per night.\\n\\n8. **Track Your Progress**: Keep a journal or use apps to monitor your workouts, nutrition, and progress towards your goals. This can help keep you motivated.\\n\\n9. **Find Activities You Enjoy**: Choose exercises that you find fun and engaging. This will make it easier to stick with your fitness routine.\\n\\n10. **Consider Professional Guidance**: If you're unsure where to start or how to progress, consider working with a personal trainer or fitness coach.\\n\\nThese tips can help you establish a solid foundation for your fitness journey.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_rag_query(\"What are the top tips for fitness?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a88ea371-575e-4c1a-bfce-4f27527fabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.integrations.langchain import CallbackHandler\n",
    "from deepeval.metrics import TaskCompletionMetric\n",
    "\n",
    "\n",
    "def run_rag_query(query: str):\n",
    "    \"\"\"Run a query through the RAG system\"\"\"\n",
    "\n",
    "    initial_state[\"messages\"] = [HumanMessage(content=query)]\n",
    "\n",
    "    result = app.invoke(\n",
    "        initial_state,\n",
    "        config={\n",
    "            \"callbacks\": [\n",
    "                CallbackHandler(\n",
    "                    metrics=[\n",
    "                        TaskCompletionMetric(strict_mode=True, async_mode=False)\n",
    "                    ]\n",
    "                )\n",
    "            ]  # pass the metrics to the callback handler\n",
    "        },\n",
    "    )\n",
    "\n",
    "    final_message = result[\"messages\"][-1]\n",
    "    return final_message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1f5e6b7-1ddb-4fea-b3ba-bf9dac41d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.dataset import EvaluationDataset, Golden\n",
    "\n",
    "dataset = EvaluationDataset(goldens=[\n",
    "    Golden(input=\"How many steps should I take a day?\"),\n",
    "    Golden(input=\"What are some ways to get more steps in on a day?\"),\n",
    "    Golden(input=\"What is a good resting heart rate?\"),\n",
    "    Golden(input=\"What range of heart rate is normal?\")\n",
    "])\n",
    "\n",
    "# Need a corporate email for this to work ... annoying.\n",
    "# dataset = EvaluationDataset()\n",
    "# dataset.pull(alias=\"health_rag_queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0e81012-2438-4256-9bbd-eb17a924baa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b283419011a84a2a888fc35ac6795a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgolden\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevals_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_rag_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgolden\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/deepeval/dataset/dataset.py:985\u001b[39m, in \u001b[36mEvaluationDataset.evals_iterator\u001b[39m\u001b[34m(self, identifier, display_config, cache_config, error_config, async_config)\u001b[39m\n\u001b[32m    983\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m async_config.run_async:\n\u001b[32m    984\u001b[39m     loop = get_or_create_event_loop()\n\u001b[32m--> \u001b[39m\u001b[32m985\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m a_execute_agentic_test_cases_from_loop(\n\u001b[32m    986\u001b[39m         goldens=goldens,\n\u001b[32m    987\u001b[39m         verbose_mode=display_config.verbose_mode,\n\u001b[32m    988\u001b[39m         ignore_errors=error_config.ignore_errors,\n\u001b[32m    989\u001b[39m         skip_on_missing_params=error_config.skip_on_missing_params,\n\u001b[32m    990\u001b[39m         show_indicator=display_config.show_indicator,\n\u001b[32m    991\u001b[39m         loop=loop,\n\u001b[32m    992\u001b[39m         throttle_value=async_config.throttle_value,\n\u001b[32m    993\u001b[39m         max_concurrent=async_config.max_concurrent,\n\u001b[32m    994\u001b[39m         test_results=test_results,\n\u001b[32m    995\u001b[39m         save_to_disk=cache_config.write_cache,\n\u001b[32m    996\u001b[39m         identifier=identifier,\n\u001b[32m    997\u001b[39m     )\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    999\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m execute_agentic_test_cases_from_loop(\n\u001b[32m   1000\u001b[39m         goldens=goldens,\n\u001b[32m   1001\u001b[39m         verbose_mode=display_config.verbose_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m         identifier=identifier,\n\u001b[32m   1008\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/deepeval/evaluate/execute.py:1768\u001b[39m, in \u001b[36ma_execute_agentic_test_cases_from_loop\u001b[39m\u001b[34m(goldens, verbose_mode, ignore_errors, skip_on_missing_params, show_indicator, test_results, loop, throttle_value, max_concurrent, save_to_disk, identifier, _use_bar_indicator, _is_assert_test)\u001b[39m\n\u001b[32m   1758\u001b[39m         pbar_id = add_pbar(\n\u001b[32m   1759\u001b[39m             progress,\n\u001b[32m   1760\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning Component-Level Evals (sync)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1761\u001b[39m             total=\u001b[38;5;28mlen\u001b[39m(goldens) * \u001b[32m2\u001b[39m,\n\u001b[32m   1762\u001b[39m         )\n\u001b[32m   1763\u001b[39m         pbar_callback_id = add_pbar(\n\u001b[32m   1764\u001b[39m             progress,\n\u001b[32m   1765\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m⚡ Calling LLM app (with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(goldens)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m goldens)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1766\u001b[39m             total=\u001b[38;5;28mlen\u001b[39m(goldens),\n\u001b[32m   1767\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1768\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m evaluate_test_cases(\n\u001b[32m   1769\u001b[39m             progress=progress,\n\u001b[32m   1770\u001b[39m             pbar_id=pbar_id,\n\u001b[32m   1771\u001b[39m             pbar_callback_id=pbar_callback_id,\n\u001b[32m   1772\u001b[39m         )\n\u001b[32m   1773\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m evaluate_test_cases()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/deepeval/evaluate/execute.py:1730\u001b[39m, in \u001b[36ma_execute_agentic_test_cases_from_loop.<locals>.evaluate_test_cases\u001b[39m\u001b[34m(progress, pbar_id, pbar_callback_id)\u001b[39m\n\u001b[32m   1711\u001b[39m     loop.run_until_complete(\n\u001b[32m   1712\u001b[39m         evaluate_test_case_pairs(\n\u001b[32m   1713\u001b[39m             test_case_pairs=openai_test_case_pairs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1727\u001b[39m         )\n\u001b[32m   1728\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m trace_manager.integration_traces_to_evaluate:\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluate_traces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1732\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtraces_to_evaluate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrace_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintegration_traces_to_evaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1733\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgoldens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgoldens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1734\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtest_run_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_run_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1735\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtest_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1736\u001b[39m \u001b[43m            \u001b[49m\u001b[43mverbose_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1737\u001b[39m \u001b[43m            \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1738\u001b[39m \u001b[43m            \u001b[49m\u001b[43mskip_on_missing_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_on_missing_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1739\u001b[39m \u001b[43m            \u001b[49m\u001b[43mshow_indicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_indicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_use_bar_indicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_use_bar_indicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_is_assert_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_is_assert_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1743\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpbar_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpbar_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[43m            \u001b[49m\u001b[43mthrottle_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthrottle_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_concurrent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1746\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1747\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/asyncio/futures.py:202\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/asyncio/tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/deepeval/evaluate/execute.py:1808\u001b[39m, in \u001b[36mevaluate_traces\u001b[39m\u001b[34m(traces_to_evaluate, goldens, test_run_manager, test_results, verbose_mode, ignore_errors, skip_on_missing_params, show_indicator, _use_bar_indicator, _is_assert_test, progress, pbar_id, throttle_value, max_concurrent)\u001b[39m\n\u001b[32m   1806\u001b[39m eval_tasks = []\n\u001b[32m   1807\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m count, trace \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(traces_to_evaluate):\n\u001b[32m-> \u001b[39m\u001b[32m1808\u001b[39m     golden = \u001b[43mgoldens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1809\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m capture_evaluation_run(\u001b[33m\"\u001b[39m\u001b[33mgolden\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1810\u001b[39m         task = execute_evals_with_semaphore(\n\u001b[32m   1811\u001b[39m             func=a_execute_agentic_test_case,\n\u001b[32m   1812\u001b[39m             golden=golden,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1824\u001b[39m             pbar_id=pbar_id,\n\u001b[32m   1825\u001b[39m         )\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "for golden in dataset.evals_iterator():\n",
    "    run_rag_query(golden.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16fea007-dc8f-4939-9e68-d232018307eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m golden \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevals_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(golden)\n",
      "\u001b[31mTypeError\u001b[39m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for golden in dataset.evals_iterator():\n",
    "    print(golden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ff3b4f9-74bb-4234-b13b-80493ce7cfab",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevals_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233ab60-0049-433a-a121-bb78e643dc11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
